---
layout: post
title:  "QFlowNet: Fast, Diverse, and Efficient Unitary Synthesis with Generative Flow Networks"
date:   2025-12-18 12:32 +0400
image:  QFlowNet-schematic.png
hide_header_image: true
tags:   Quantum Computing
---
![QFlowNet Schematic](/images/QFlowNet-schematic.png)

### *QFlowNet: Fast, Diverse, and Efficient Unitary Synthesis with Generative Flow Networks*

> **"Finding not just one solution, but a diverse landscape of compact quantum circuits."**

### ðŸ’¡ The Problem: The Compilation Challenge
Decomposing a target unitary $U$ into a sequence of gates (Unitary Synthesis) is a combinatorial problem with a search space growing as $G^l$. Existing ML approaches face a critical trade-off:
1.  **RL (e.g., AlphaZero):** Suffers from sparse rewards (fidelity is a "cliff") and converges to a single deterministic policy, lacking diversity.
2.  **Diffusion Models:** Provide diversity but require slow, iterative inference, making them impractical for on-the-fly compilation.

### ðŸš€ Key Innovation: GFlowNets + Transformers
I developed **QFlowNet**, a framework pairing **Generative Flow Networks (GFlowNets)** with **Transformers** to learn a policy that samples circuit candidates proportional to their reward.

We reframe synthesis as a path-finding problem to a **universal goal**:
$$s_t = U V_t^\dagger \xrightarrow{\text{Action } a_t} s_{t+1} \dots \xrightarrow{\text{Terminal}} I$$

* **Universal Goal:** Instead of learning a target-specific function, the agent learns to reduce the "unitary residual" to the Identity matrix ($I$). This allows a single trained policy to synthesize *any* target unitary.
* **Transformer Encoder:** Captures the non-local structure of the unitary matrix, compressing high-dimensional states into dense latent representations for the policy.

### Why It Matters
QFlowNet establishes a new standard for efficient and diverse synthesis.
* **Diversity & Compactness:** Unlike RL, it generates a diverse set of high-fidelity candidates, often discovering circuits more compact than standard compilers.
* **Speed:** It overcomes the slow inference of diffusion models while handling the sparse reward landscape effectively.
* **Performance:** Achieved a **99.7% success rate** on 3-qubit benchmarks for circuit lengths 1â€“12.

[jekyll-docs]: https://inaekoo.github.io
[jekyll-gh]:   https://github.com/InaeKoo
